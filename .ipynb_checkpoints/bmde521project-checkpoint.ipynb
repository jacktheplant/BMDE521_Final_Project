{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d511d8ec-4c50-4742-986f-3691d78ab3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install scanpy muon mudata python-igraph leidenalg scikit-learn networkx jupyterlab ipywidgets scikit-image -y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfee1530-32e7-4904-b1d2-efcef5be2ff5",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8645308f-df11-4b9e-acb2-663c0d118955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import muon as mu\n",
    "import scanpy as sc\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import time\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import warnings\n",
    "# Ignore FutureWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "# Ignore UserWarnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "from mudata import MuData # multi layer handling\n",
    "from anndata import AnnData\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f6ed4f-ead7-442e-b5e6-9f355fe45a6b",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "36644daf-d3b7-4b27-a832-702f7a632028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing pipeline\n",
    "\n",
    "def preprocessing(mdata, verbose=False):\n",
    "\n",
    "    # calculate QC metrics for RNA\n",
    "    # based on assignment 2 - n_genes_by_counts, total_counts, pct_counts_mt\n",
    "    mdata['rna'].var['mt'] = mdata['rna'].var_names.str.startswith('MT-')\n",
    "    sc.pp.calculate_qc_metrics(mdata['rna'], qc_vars=['mt'], percent_top=None, log1p=False, inplace=True)\n",
    "\n",
    "    if(verbose == True):\n",
    "        print(f\"Number of cells before filtering: {mdata.shape[0]}\")\n",
    "\n",
    "    # filter cells\n",
    "    # remove cells based on metrics in the rna set (too few genes or too few cells)\n",
    "    sc.pp.filter_cells(mdata['rna'], min_genes=200)\n",
    "    sc.pp.filter_genes(mdata['rna'], min_cells=3)\n",
    "\n",
    "    # remove high mt content and high gene count outliers\n",
    "    \n",
    "    gene_thresh = mdata['rna'].obs.n_genes_by_counts < 4000\n",
    "    mitochondria_thresh = mdata['rna'].obs.pct_counts_mt < 6\n",
    "\n",
    "    mdata = mdata[gene_thresh & mitochondria_thresh, :].copy()\n",
    "\n",
    "    if (verbose==True):\n",
    "        print(f\"Number of cells after filtering: {mdata.shape[0]}\")\n",
    "\n",
    "    # doublet removal\n",
    "    if (verbose==True):\n",
    "        print(\"Checking for doublets. This may take a while...\")\n",
    "        start_time = time.time()\n",
    "\n",
    "    n_doublets = sc.pp.scrublet(mdata['rna'])\n",
    "    mdata = mdata[mdata['rna'].obs['predicted_doublet'] == False, :].copy()\n",
    "\n",
    "    if verbose==True:\n",
    "        print(f\"Doublet removal complete. Time elapsed: {time.time() - start_time} s\")\n",
    "        print(f\"Number of cells after doublet removal: {mdata.shape[0]}\") \n",
    "\n",
    "    # log norm\n",
    "    sc.pp.normalize_total(mdata['rna'], target_sum=1e4)\n",
    "    sc.pp.log1p(mdata['rna'])\n",
    "\n",
    "    if (verbose==True):\n",
    "        print(f\"Number of genes before highly variable genes selection: {mdata['rna'].shape[1]}\") \n",
    "\n",
    "    # filtering for highly variable genes\n",
    "    sc.pp.highly_variable_genes(mdata['rna'], n_top_genes=2000, subset=True) \n",
    "\n",
    "    if (verbose==True):\n",
    "        print(f\"Number of genes after highly variable genes selection: {mdata['rna'].shape[1]}\") \n",
    "\n",
    "    # dimensionality reduction\n",
    "\n",
    "    # pca for rna set\n",
    "    sc.pp.pca(mdata['rna'], n_comps=20)\n",
    "    # tfidf and lso for atac\n",
    "    mu.atac.pp.tfidf(mdata['atac'], scale_factor=1e4)\n",
    "    mu.atac.tl.lsi(mdata['atac'], n_comps=20)\n",
    "\n",
    "    # compute neighbourhood graphs\n",
    "\n",
    "    sc.pp.neighbors(mdata['rna'], n_neighbors=30, key_added='rna')\n",
    "    sc.pp.neighbors(mdata['atac'], use_rep='X_lsi', n_neighbors=30, key_added='atac')\n",
    "\n",
    "    return mdata\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab180b-916b-43bf-95c2-5766c1900e9a",
   "metadata": {},
   "source": [
    "# Entropy Weighted Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c5fc92f5-4680-4f29-9c19-5dc67a692437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "# this function converts affinities into transition probabilities (Markov normalization)\n",
    "def compute_transition_matrix(adj_matrix, verbose=False):\n",
    "\n",
    "    if(verbose==True):\n",
    "        print(\"Adjacency matrix:\")\n",
    "        print(adj_matrix.toarray())\n",
    "\n",
    "    # calculate row sums \n",
    "    row_sums = np.array(adj_matrix.sum(axis=1)).flatten()\n",
    "    row_sums[row_sums == 0] = 1 # prevent dividing by zero\n",
    "\n",
    "    if(verbose==True):\n",
    "        print(\"Row sum:\")\n",
    "        print(row_sums)\n",
    "    \n",
    "\n",
    "    # compute the inverse diagonal matrix using row sum reciprocals\n",
    "    diagonal = sparse.diags(1.0 / row_sums)\n",
    "    if(verbose==True):\n",
    "        print(\"Diagonal matrix:\")\n",
    "        print(diagonal.toarray())\n",
    "    \n",
    "    # multiply the diagonal matrix by the adjacency matrix to perform Markov's normalization\n",
    "    markov = diagonal.dot(adj_matrix)\n",
    "\n",
    "    if(verbose==True):\n",
    "        print(\"Markov normalized matrix:\")\n",
    "        print(markov.toarray())\n",
    "    \n",
    "    return markov\n",
    "\n",
    "\n",
    "# calculate graph entropy to detect noisy cells \n",
    "def calculate_uncertainty_weights(adj_matrix, verbose=False):\n",
    "\n",
    "    if verbose==True:\n",
    "        print(\"Adjacency matrix:\")\n",
    "        print(adj_matrix.toarray())\n",
    "    \n",
    "    # Get probabilities\n",
    "    prob = compute_transition_matrix(adj_matrix)\n",
    "\n",
    "    if verbose==True:\n",
    "        print(\"Probability matrix:\")\n",
    "        print(prob.toarray())\n",
    "    \n",
    "    # calculate the entropy of each row\n",
    "    ent = entropy(prob.toarray().T)\n",
    "\n",
    "    if verbose==True:\n",
    "        print(\"Entropy array:\")\n",
    "        print(ent)\n",
    "\n",
    "    # get inverse of weights (cells with lower entropy are weighted higher)\n",
    "    weights = np.exp(-ent)\n",
    "\n",
    "    if verbose==True:\n",
    "        print(\"Weights:\")\n",
    "        print(weights)\n",
    "\n",
    "    return weights\n",
    "\n",
    "# fusion algorithm\n",
    "def fuse_graphs(mdata, steps=20, verbose=False):\n",
    "\n",
    "    # first, get affinity graphs\n",
    "    rna = mdata['rna'].obsp['rna_distances']\n",
    "    atac = mdata['atac'].obsp['atac_distances']\n",
    "\n",
    "    # calculate weights\n",
    "    rna_weights = calculate_uncertainty_weights(rna)\n",
    "    atac_weights = calculate_uncertainty_weights(atac)\n",
    "\n",
    "    # normalize weights \n",
    "    total_weights = rna_weights + atac_weights\n",
    "    norm_rna_weights = (rna_weights / total_weights)[:, None] # reshape is necessary for later steps\n",
    "    norm_atac_weights = (atac_weights / total_weights)[:, None] \n",
    "    \n",
    "    if verbose==True:\n",
    "        print(f\"New shape of rna weights array: {norm_rna_weights.shape}\")\n",
    "        print(f\"New shape of atac weights array: {norm_atac_weights.shape}\")\n",
    "\n",
    "    print(f\"Average RNA Trust: {np.mean(norm_rna_weights):.2f}\")\n",
    "    print(f\"Average ATAC Trust: {np.mean(norm_atac_weights):.2f}\")\n",
    "\n",
    "    # rather than initializing the fused matrix to be 50/50 rna and atac, this initial guess\n",
    "    # utilizes the entropy weights to weight the matrices on a per cell basis\n",
    "\n",
    "    # the probability matrices \n",
    "    rna_prob = compute_transition_matrix(rna)\n",
    "    atac_prob = compute_transition_matrix(atac)\n",
    "\n",
    "    fused_probability = (rna_prob.multiply(norm_rna_weights) + atac_prob.multiply(norm_atac_weights))\n",
    "\n",
    "    # diffusion loop (Similarity Network Fusion)\n",
    "    for i in range(steps):\n",
    "        # update\n",
    "        diff = (rna_prob.multiply(norm_rna_weights)) + (atac_prob.multiply(norm_atac_weights)) # need to multiply by original at each step\n",
    "\n",
    "        # updated fused prob graph and normalize\n",
    "        fused_probability = diff.dot(fused_probability).dot(diff.T) # using the transposed version as well to enforce symmetry\n",
    "        fused_probability = compute_transition_matrix(fused_probability)\n",
    "\n",
    "    return fused_probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca68b7c-33f5-4ea9-8201-eb6d8337910c",
   "metadata": {},
   "source": [
    "# Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "686d3108-9275-458d-84a4-0c6baa8e5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation is similar to MAGIC, but uses the fused graph instead of a standard markov normalized probability matrix\n",
    "def impute_atac(mdata, fused_probability, t=3):\n",
    "    \"\"\"\n",
    "    Formula: D_imputed = (fused_probability)^3 * D\n",
    "    \"\"\"\n",
    "\n",
    "    atac = mdata['atac'].X.copy()\n",
    "    imputed = atac\n",
    "\n",
    "    for i in range(t):\n",
    "        imputed = fused_probability.dot(imputed)\n",
    "\n",
    "    # store in mdata\n",
    "    mdata['atac'].layers['imputed'] = imputed\n",
    "    print(\"Imputation complete and stored in mdata['atac'].layers['imputed']\")\n",
    "    \n",
    "    return imputed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb49505-87c0-4af9-8364-93960cef5477",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "568813d8-9a6a-44d9-b2ed-b7c993b1c2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Transition Matrix---\n",
      "\n",
      "Adjacency matrix:\n",
      "[[0 2 8]\n",
      " [5 0 5]\n",
      " [1 1 0]]\n",
      "Row sum:\n",
      "[10 10  2]\n",
      "Diagonal matrix:\n",
      "[[0.1 0.  0. ]\n",
      " [0.  0.1 0. ]\n",
      " [0.  0.  0.5]]\n",
      "Markov normalized matrix:\n",
      "[[0.  0.2 0.8]\n",
      " [0.5 0.  0.5]\n",
      " [0.5 0.5 0. ]]\n",
      "\n",
      "---Weights---\n",
      "\n",
      "Adjacency matrix:\n",
      "[[0 2 8]\n",
      " [5 0 5]\n",
      " [1 1 0]]\n",
      "Probability matrix:\n",
      "[[0.  0.2 0.8]\n",
      " [0.5 0.  0.5]\n",
      " [0.5 0.5 0. ]]\n",
      "Entropy array:\n",
      "[0.50040242 0.69314718 0.69314718]\n",
      "Weights:\n",
      "[0.60628663 0.5        0.5       ]\n"
     ]
    }
   ],
   "source": [
    "# testing compute_transition_matrix \n",
    "print(\"---Transition Matrix---\\n\")\n",
    "\n",
    "test_matrix = np.array([\n",
    "    [0, 2, 8],\n",
    "    [5, 0, 5],\n",
    "    [1, 1, 0]\n",
    "])\n",
    "\n",
    "sparse_test_matrix = sparse.csr_matrix(test_matrix)\n",
    "\n",
    "test = compute_transition_matrix(sparse_test_matrix, verbose=True)\n",
    "\n",
    "# works as expected!\n",
    "\n",
    "# testing calculate_uncertainty_weights\n",
    "print(\"\\n---Weights---\\n\")\n",
    "weights = calculate_uncertainty_weights(sparse_test_matrix, verbose=True)\n",
    "\n",
    "# works as expected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e017fbc-cb65-452b-9633-7991782edb79",
   "metadata": {},
   "source": [
    "# Validation with Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c57f92f-8557-415a-91aa-39b1fea6ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data that mimics data with cell types to see if pipeline can preserve cell types\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# 3 cell types. rna data will have tight clusters, while atac data will have wider spread clusters (representing higher noise)\n",
    "\n",
    "rna_mock, labels = make_blobs(n_samples=1000, n_features=3000, centers=3, cluster_std=2)\n",
    "atac_mock, _ = make_blobs(n_samples=1000, n_features=10000, centers=3, cluster_std=15)\n",
    "\n",
    "# need positive values\n",
    "rna_mock = np.abs(rna_mock)\n",
    "atac_mock = np.abs(atac_mock)\n",
    "\n",
    "rna_mock_ann = AnnData(rna_mock, obs={\"cell_type\": labels.astype(str)})\n",
    "atac_mock_ann = AnnData(atac_mock, obs={\"cell_type\": labels.astype(str)})\n",
    "mdata_mock = MuData({\"rna\": rna_mock_ann, \"atac\": atac_mock_ann})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22093a82-2021-4df2-b2d9-bab09b35054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def imputation_validation(mdata, fused_probability, t=3):\n",
    "    print(\"Dropout Validation\")\n",
    "    ground_truth = mdata['atac'].X.copy()\n",
    "\n",
    "    # next, we corrupt the data by simulating a 40% dropout\n",
    "    mask = np.random.choice([0, 1], size=ground_truth.shape, p=[0.4, 0.6]) # 40% chance of 0 (dropout)\n",
    "    corrupted = ground_truth.toarray() * mask\n",
    "\n",
    "    # temporarily inject corrupted data\n",
    "    mdata['atac'].X = sparse.csr_matrix(corrupted)\n",
    "\n",
    "    imputed_matrix = impute_atac(mdata, fused_probability, t=3)\n",
    "\n",
    "    # restore original data\n",
    "    mdata['atac'].X = ground_truth\n",
    "\n",
    "    # check drop out spots\n",
    "    dropout_mask = (mask == 0)\n",
    "    true_values = ground_truth.toarray()[dropout_mask]\n",
    "    if sparse.issparse(imputed_matrix):\n",
    "        imputed_values = imputed_matrix.toarray()[dropout_mask]\n",
    "    else:\n",
    "        imputed_values = imputed_matrix[dropout_mask]\n",
    "\n",
    "    # now we simply compare \n",
    "    mse = mean_squared_error(true_values, imputed_values)\n",
    "\n",
    "    # calculate what the mse would have without any fixing\n",
    "    baseline_mse = mean_squared_error(true_values, np.zeros_like(true_values))\n",
    "\n",
    "    print(\"Results\")\n",
    "    print(f\"Baseline MSE: {baseline_mse:.4f}\")\n",
    "    print(f\"Imputed MSE: {mse:.4f}\")\n",
    "\n",
    "    improvement = (baseline_mse - mse) / baseline_mse * 100\n",
    "    print(f\"Improvement: {improvement:.4f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ea7907a-4ed8-4cb9-b0d0-19e1ae9eb662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cells before filtering: 1000\n",
      "Number of cells after filtering: 1000\n",
      "Checking for doublets. This may take a while...\n",
      "Doublet removal complete. Time elapsed: 0.28804922103881836 s\n",
      "Number of cells after doublet removal: 996\n",
      "Number of genes before highly variable genes selection: 3000\n",
      "Number of genes after highly variable genes selection: 2000\n",
      "New shape of rna weights array: (996, 1)\n",
      "New shape of atac weights array: (996, 1)\n",
      "Average RNA Trust: 0.50\n",
      "Average ATAC Trust: 0.50\n",
      "Dropout Validation\n",
      "Imputation complete and stored in mdata['atac'].layers['imputed']\n",
      "Results\n",
      "Baseline MSE: 0.0029\n",
      "Imputed MSE: 0.0011\n",
      "Improvement: 63.1632%\n"
     ]
    }
   ],
   "source": [
    "# mock data validation\n",
    "\n",
    "mdata_mock = preprocessing(mdata_mock, verbose=True)\n",
    "\n",
    "fused_mock = fuse_graphs(mdata_mock, steps=20, verbose=True)\n",
    "\n",
    "imputation_validation(mdata_mock, fused_mock, t=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34554a5f-aca2-43c1-9413-44a54b2546fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f126b14c-5c6a-411e-bb68-4b083d2f6904",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c5fae6-7465-4b25-95be-65e8ea25b2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46136885-f573-4406-ae7f-200e16eeec53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (BMDE 521)",
   "language": "python",
   "name": "bmde521"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
